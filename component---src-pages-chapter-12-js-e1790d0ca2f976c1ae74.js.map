{"version":3,"file":"component---src-pages-chapter-12-js-e1790d0ca2f976c1ae74.js","mappings":"mJA8BA,IA3BeA,IAAwC,IAAvC,SAAEC,EAAQ,YAAEC,GAAc,GAAOF,EAC/C,OACEG,EAAAA,cAAAA,EAAAA,SAAA,KACEA,EAAAA,cAAA,OACEC,MAAO,CACLC,OAAQ,SACRC,SAAUJ,EAAc,OAAS,sBACjCK,QAASL,EAAc,IAAM,uBAG/BC,EAAAA,cAAA,YAAOF,IACLC,GACAC,EAAAA,cAAA,UACEC,MAAO,CACLI,UAAW,iBACXC,SAAU,iBACVC,MAAO,SAEV,MACI,IAAIC,MAAOC,cAAc,iCAIjC,C,qECvBA,SAASC,EAAIb,GAA+B,IAA9B,MAAEc,EAAK,YAAEC,EAAc,IAAIf,EAC9C,MAAMgB,EAAY,qBACZC,EAAkBF,GAAe,kCAIvC,OACEZ,EAAAA,cAAAA,EAAAA,SAAA,KACEA,EAAAA,cAAA,aAAQW,EAAQ,GAAGA,OAAWE,IAAcA,GAC5Cb,EAAAA,cAAA,QAAMe,KAAK,cAAcC,QAASF,IAClCd,EAAAA,cAAA,QAAMiB,SAAS,WAAWD,QAASL,GAASE,IAC5Cb,EAAAA,cAAA,QAAMiB,SAAS,iBAAiBD,QAASF,IACzCd,EAAAA,cAAA,QAAMiB,SAAS,UAAUD,QAAQ,YACjChB,EAAAA,cAAA,QAAMiB,SAAS,SAASD,QAVZ,qDAWZhB,EAAAA,cAAA,QAAMe,KAAK,eAAeC,QAAQ,YAClChB,EAAAA,cAAA,QAAMe,KAAK,kBAAkBC,QAXlB,kBAYXhB,EAAAA,cAAA,QAAMe,KAAK,gBAAgBC,QAASL,GAASE,IAC7Cb,EAAAA,cAAA,QAAMe,KAAK,sBAAsBC,QAASF,IAGhD,C,gKCpBA,MAAMI,GAASC,EAAAA,EAAAA,WAAS,uFAWlBC,EAAOC,EAAAA,QAAOC,IAAGC,WAAA,CAAAC,YAAA,4BAAAC,YAAA,gBAAVJ,CAAU,2PASRH,GAQTQ,EAASL,EAAAA,QAAOM,OAAMJ,WAAA,CAAAC,YAAA,8BAAAC,YAAA,gBAAbJ,CAAa,qMAoB5B,MAAMO,EAAa,CAEX,CAAEC,SAAU,0BAA2BC,OAAQ,sFAC/C,CAAED,SAAU,4BAA6BC,OAAQ,0EACjD,CAAED,SAAU,uCAAwCC,OAAQ,sDAC5D,CAAED,SAAU,gCAAiCC,OAAQ,qDACrD,CAAED,SAAU,0BAA2BC,OAAQ,qEAC/C,CAAED,SAAU,gCAAiCC,OAAQ,gEACrD,CAAED,SAAU,0CAA2CC,OAAQ,kEAC/D,CAAED,SAAU,8BAA+BC,OAAQ,2DACnD,CAAED,SAAU,uCAAwCC,OAAQ,kEAC5D,CAAED,SAAU,uCAAwCC,OAAQ,wDAC5D,CAAED,SAAU,oCAAqCC,OAAQ,0EACzD,CAAED,SAAU,sCAAuCC,OAAQ,mEAC3D,CAAED,SAAU,iCAAkCC,OAAQ,mFACtD,CAAED,SAAU,4BAA6BC,OAAQ,mFACjD,CAAED,SAAU,qCAAsCC,OAAQ,4DAC1D,CAAED,SAAU,6BAA8BC,OAAQ,kEAClD,CAAED,SAAU,6BAA8BC,OAAQ,sDAClD,CAAED,SAAU,mCAAoCC,OAAQ,yEACxD,CAAED,SAAU,4CAA6CC,OAAQ,2EACjE,CAAED,SAAU,8CAA+CC,OAAQ,+DACnE,CAAED,SAAU,4CAA6CC,OAAQ,uEACjE,CAAED,SAAU,+BAAgCC,OAAQ,2DACpD,CAAED,SAAU,uDAAwDC,OAAQ,yDAC5E,CAAED,SAAU,+BAAgCC,OAAQ,uDACpD,CAAED,SAAU,qCAAsCC,OAAQ,0DAC1D,CAAED,SAAU,2BAA4BC,OAAQ,oEAChD,CAAED,SAAU,sDAAuDC,OAAQ,yCAC3E,CAAED,SAAU,oDAAqDC,OAAQ,gEACzE,CAAED,SAAU,wBAAyBC,OAAQ,0DAC7C,CAAED,SAAU,8CAA+CC,OAAQ,4DAI5D,SAASC,IACtB,MAAOC,GAAiBhC,EAAAA,UAAe,KAAMiC,OAxCzBC,EAwCsCN,GAvCnDO,EAAAA,EAAAA,GAAID,GAAOE,MAAK,IAAMC,KAAKC,SAAW,KAD/C,IAAsBJ,CAwCiD,KAC9DK,EAAOC,GAAYxC,EAAAA,SAAe,IAClCyC,EAAYC,GAAiB1C,EAAAA,UAAe,GAOnD,OACEA,EAAAA,cAACoB,EAAI,KACHpB,EAAAA,cAAA,UAAI,gBAAcuC,EAAQ,EAAE,OAAKP,EAAcW,QAC/C3C,EAAAA,cAAA,SAAIgC,EAAcO,GAAOV,UACxBY,GAAczC,EAAAA,cAAA,SAAGA,EAAAA,cAAA,cAAQ,WAAgB,IAAEgC,EAAcO,GAAOT,QACjE9B,EAAAA,cAAA,WACEA,EAAAA,cAAC0B,EAAM,CAACkB,QAASA,IAAMF,GAAeG,IAAUA,KAC7CJ,EAAa,cAAgB,eAEhCzC,EAAAA,cAAC0B,EAAM,CAACkB,QAdGE,KACfJ,GAAc,GACdF,GAAUK,IAAUA,EAAO,GAAKb,EAAcW,QAAO,EAYtB1C,MAAO,CAAE8C,WAAY,SAAU,SAMlE,CCtGA,MAAMC,EAAc3B,EAAAA,QAAOC,IAAGC,WAAA,CAAAC,YAAA,0BAAAC,YAAA,eAAVJ,CAAU,wOAoBxB4B,EAAU5B,EAAAA,QAAOC,IAAGC,WAAA,CAAAC,YAAA,sBAAAC,YAAA,eAAVJ,CAAU,qdAyCX,SAAS6B,IACtB,OACElD,EAAAA,cAACmD,EAAAA,EAAM,KACLnD,EAAAA,cAACiD,EAAO,KACNjD,EAAAA,cAAA,UAAI,4CAEJA,EAAAA,cAAA,SAAG,mNAEHA,EAAAA,cAAA,UAAI,wCACJA,EAAAA,cAAA,UACEA,EAAAA,cAAA,UAAIA,EAAAA,cAAA,cAAQ,aAAkB,6DAC9BA,EAAAA,cAAA,UAAIA,EAAAA,cAAA,cAAQ,iBAAsB,sEAClCA,EAAAA,cAAA,UAAIA,EAAAA,cAAA,cAAQ,mBAAwB,oEACpCA,EAAAA,cAAA,UAAIA,EAAAA,cAAA,cAAQ,YAAiB,kDAC7BA,EAAAA,cAAA,UAAIA,EAAAA,cAAA,cAAQ,aAAkB,6CAGhCA,EAAAA,cAAA,UAAI,+BACJA,EAAAA,cAAA,UACEA,EAAAA,cAAA,UAAI,8EACJA,EAAAA,cAAA,UAAI,uEACJA,EAAAA,cAAA,UAAI,6CACJA,EAAAA,cAAA,UAAI,+EAGNA,EAAAA,cAAA,UAAI,wCACJA,EAAAA,cAAA,SAAG,iEACHA,EAAAA,cAAA,UACEA,EAAAA,cAAA,UAAIA,EAAAA,cAAA,cAAQ,SAAc,mDAC1BA,EAAAA,cAAA,UAAIA,EAAAA,cAAA,cAAQ,SAAc,wDAC1BA,EAAAA,cAAA,UAAIA,EAAAA,cAAA,cAAQ,gBAAqB,oEAGnCA,EAAAA,cAAA,UAAI,gCACJA,EAAAA,cAAA,UACEA,EAAAA,cAAA,UAAI,yDACJA,EAAAA,cAAA,UAAI,0CACJA,EAAAA,cAAA,UAAI,OAAIA,EAAAA,cAAA,YAAM,MAAS,gBAAaA,EAAAA,cAAA,YAAM,OAAU,wCAGtDA,EAAAA,cAAA,UAAI,8BACJA,EAAAA,cAAA,UACEA,EAAAA,cAAA,UAAI,4CAAyCA,EAAAA,cAAA,cAAQ,kCAAuC,KAC5FA,EAAAA,cAAA,UAAI,wCACJA,EAAAA,cAAA,UAAI,6DAGNA,EAAAA,cAAA,UAAI,2BACJA,EAAAA,cAAA,UACEA,EAAAA,cAAA,UAAI,6DACJA,EAAAA,cAAA,UAAI,iEACJA,EAAAA,cAAA,UAAI,gEAGNA,EAAAA,cAAA,UAAI,wCACJA,EAAAA,cAAA,OAAKoD,UAAU,WAAW,yQAc1BpD,EAAAA,cAAA,UAAI,mBACJA,EAAAA,cAAA,UACEA,EAAAA,cAAA,UAAI,kFACJA,EAAAA,cAAA,UAAI,oEACJA,EAAAA,cAAA,UAAI,4FAGNA,EAAAA,cAAC+B,EAAmB,MACZ/B,EAAAA,cAACgD,EAAW,KACHhD,EAAAA,cAACqD,EAAAA,GAAI,CAACC,GAAG,oBAAmB,WAC5BtD,EAAAA,cAACqD,EAAAA,GAAI,CAACC,GAAG,KAAI,qBAKtC,C","sources":["webpack://gatsby-starter-default/./src/components/layout.js","webpack://gatsby-starter-default/./src/components/seo.js","webpack://gatsby-starter-default/./src/components/FlashcardsChapter12.js","webpack://gatsby-starter-default/./src/pages/chapter-12.js"],"sourcesContent":["import * as React from \"react\"\nimport \"./layout.css\"\n\nconst Layout = ({ children, isFullWidth = false }) => {\n  return (\n    <>\n      <div\n        style={{\n          margin: \"0 auto\",\n          maxWidth: isFullWidth ? \"100%\" : \"var(--size-content)\",\n          padding: isFullWidth ? \"0\" : \"var(--size-gutter)\",\n        }}\n      >\n        <main>{children}</main>\n        {!isFullWidth && (\n          <footer\n            style={{\n              marginTop: `var(--space-5)`,\n              fontSize: `var(--font-sm)`,\n              color: \"#888\",\n            }}\n          >\n            © {new Date().getFullYear()} · Built for AWS AI learners\n          </footer>\n        )}\n      </div>\n    </>\n  )\n}\n\nexport default Layout\n","// src/components/seo.js\nimport * as React from \"react\"\n\nexport function Head({ title, description = \"\" }) {\n  const siteTitle = \"AWS AI Study Guide\"\n  const siteDescription = description || \"Interactive learning for AWS AI\"\n  const siteUrl = \"https://saianeesh01.github.io/aws-ai-study-guide\"\n  const author = \"Aneesh Mussim\"\n\n  return (\n    <>\n      <title>{title ? `${title} | ${siteTitle}` : siteTitle}</title>\n      <meta name=\"description\" content={siteDescription} />\n      <meta property=\"og:title\" content={title || siteTitle} />\n      <meta property=\"og:description\" content={siteDescription} />\n      <meta property=\"og:type\" content=\"website\" />\n      <meta property=\"og:url\" content={siteUrl} />\n      <meta name=\"twitter:card\" content=\"summary\" />\n      <meta name=\"twitter:creator\" content={author} />\n      <meta name=\"twitter:title\" content={title || siteTitle} />\n      <meta name=\"twitter:description\" content={siteDescription} />\n    </>\n  )\n}\n","import * as React from \"react\"\nimport styled, { keyframes } from \"styled-components\"\n\nconst fadeIn = keyframes`\n  from {\n    opacity: 0;\n    transform: translateY(10px);\n  }\n  to {\n    opacity: 1;\n    transform: translateY(0);\n  }\n`\n\nconst Card = styled.div`\n  background: #111;\n  border: 1px solid #00ff90;\n  border-radius: 10px;\n  padding: 2rem;\n  margin-bottom: 1rem;\n  text-align: center;\n  font-family: \"Courier New\", monospace;\n  color: #00ff90;\n  animation: ${fadeIn} 0.5s ease;\n  transition: transform 0.4s ease;\n\n  &:hover {\n    transform: scale(1.02);\n  }\n`\n\nconst Button = styled.button`\n  background: #00ff90;\n  color: black;\n  border: none;\n  padding: 0.6rem 1.2rem;\n  margin-top: 1rem;\n  border-radius: 6px;\n  font-weight: bold;\n  cursor: pointer;\n  transition: background 0.3s ease;\n\n  &:hover {\n    background: #00cc70;\n  }\n`\n\nfunction shuffleArray(array) {\n  return [...array].sort(() => Math.random() - 0.5)\n}\n\nconst flashcards = [\n\n        { question: \"What is Responsible AI?\", answer: \"A practice of designing and deploying AI systems that are ethical, fair, and safe.\" },\n        { question: \"What is algorithmic bias?\", answer: \"When an ML model produces unfair outcomes due to biased training data.\" },\n        { question: \"How does AWS SageMaker Clarify help?\", answer: \"It detects bias in datasets and model predictions.\" },\n        { question: \"What is explainability in ML?\", answer: \"Making model predictions interpretable to humans.\" },\n        { question: \"What is model fairness?\", answer: \"Ensuring predictions don’t systematically disadvantage any group.\" },\n        { question: \"What is differential privacy?\", answer: \"Protecting individual data by introducing statistical noise.\" },\n        { question: \"Why is diverse training data important?\", answer: \"To reduce bias and ensure the model generalizes across groups.\" },\n        { question: \"What is transparency in AI?\", answer: \"Open communication about how models are built and used.\" },\n        { question: \"What is the impact of biased labels?\", answer: \"They can reinforce societal inequalities in model predictions.\" },\n        { question: \"Why is human review essential in AI?\", answer: \"To validate outputs and prevent automation failures.\" },\n        { question: \"What does 'black-box model' mean?\", answer: \"A model whose internal decision-making logic is not easily understood.\" },\n        { question: \"What is fairness through awareness?\", answer: \"Using group information to ensure equal treatment and outcomes.\" },\n        { question: \"What are protected attributes?\", answer: \"Features like race, gender, or age that require special handling to avoid bias.\" },\n        { question: \"What is disparate impact?\", answer: \"When a model disproportionately harms a specific group even if unintentionally.\" },\n        { question: \"What is proactive bias mitigation?\", answer: \"Addressing bias at the design and training stages of ML.\" },\n        { question: \"What is post-hoc analysis?\", answer: \"Bias or explainability evaluations after the model is trained.\" },\n        { question: \"Why track model decisions?\", answer: \"For accountability, compliance, and future audits.\" },\n        { question: \"What is fairness-aware training?\", answer: \"Training methods that enforce fairness constraints or regularization.\" },\n        { question: \"Why does under-representation cause bias?\", answer: \"The model may not learn accurate patterns for under-represented groups.\" },\n        { question: \"What is 'equal opportunity' in ML fairness?\", answer: \"Ensuring equal true positive rates across different groups.\" },\n        { question: \"What is the role of a fairness dashboard?\", answer: \"To visualize and monitor fairness metrics during model development.\" },\n        { question: \"What is individual fairness?\", answer: \"Similar individuals should receive similar predictions.\" },\n        { question: \"What’s the downside of optimizing only for accuracy?\", answer: \"It may sacrifice fairness and ignore minority errors.\" },\n        { question: \"What is model introspection?\", answer: \"Analyzing how input features influence predictions.\" },\n        { question: \"What are ethical guidelines in AI?\", answer: \"Principles to guide responsible design and deployment.\" },\n        { question: \"What is unintended bias?\", answer: \"Bias that arises from subtle or hidden issues in data or design.\" },\n        { question: \"What does SageMaker Clarify use for explainability?\", answer: \"SHAP (SHapley Additive exPlanations).\" },\n        { question: \"What is the benefit of feature importance scores?\", answer: \"They help explain model decisions and detect potential bias.\" },\n        { question: \"What is auditability?\", answer: \"The ability to trace how a model was trained and used.\" },\n        { question: \"Why should AI developers test for fairness?\", answer: \"To ensure ethical, legal, and inclusive model outcomes.\" }\n      ]\n      \n\nexport default function FlashcardsChapter12() {\n  const [shuffledCards] = React.useState(() => shuffleArray(flashcards))\n  const [index, setIndex] = React.useState(0)\n  const [showAnswer, setShowAnswer] = React.useState(false)\n\n  const nextCard = () => {\n    setShowAnswer(false)\n    setIndex((prev) => (prev + 1) % shuffledCards.length)\n  }\n\n  return (\n    <Card>\n      <h2>🧠 Flashcard {index + 1} of {shuffledCards.length}</h2>\n      <p>{shuffledCards[index].question}</p>\n      {showAnswer && <p><strong>Answer:</strong> {shuffledCards[index].answer}</p>}\n      <div>\n        <Button onClick={() => setShowAnswer((prev) => !prev)}>\n          {showAnswer ? \"Hide Answer\" : \"Show Answer\"}\n        </Button>\n        <Button onClick={nextCard} style={{ marginLeft: \"1rem\" }}>\n          Next\n        </Button>\n      </div>\n    </Card>\n  )\n}\n","// src/pages/chapter-12.js\n\nimport * as React from \"react\"\nimport Layout from \"../components/layout\"\nimport { Head } from \"../components/seo\"\nimport styled from \"styled-components\"\nimport { Link } from \"gatsby\"\nimport FlashcardsChapter12 from \"../components/FlashcardsChapter12\"\n\nconst ButtonGroup = styled.div`\n  margin-top: 3rem;\n  display: flex;\n  gap: 1rem;\n  flex-wrap: wrap;\n\n  a {\n    background: #00ff90;\n    color: black;\n    padding: 0.75rem 1.5rem;\n    border-radius: 8px;\n    text-decoration: none;\n    font-weight: bold;\n    transition: background 0.3s ease;\n\n    &:hover {\n      background: #00cc70;\n    }\n  }\n`\nconst Wrapper = styled.div`\n  background: black;\n  color: #00ff90;\n  font-family: \"Courier New\", monospace;\n  padding: 3rem 2rem;\n  min-height: 100vh;\n\n  h1, h2, h3 {\n    color: #00ff90;\n    margin-top: 2rem;\n  }\n\n  p, li {\n    line-height: 1.7;\n  }\n\n  ul {\n    margin-left: 1.5rem;\n  }\n\n  code, pre {\n    background: #111;\n    color: #00ffcc;\n    padding: 0.5rem;\n    border-radius: 6px;\n    display: block;\n    overflow-x: auto;\n    margin-top: 1rem;\n  }\n\n  .diagram {\n    margin-top: 2rem;\n    padding: 1rem;\n    border: 2px dashed #00ff90;\n    background: #111;\n    border-radius: 10px;\n    white-space: pre-wrap;\n    font-family: \"Courier New\", monospace;\n  }\n`;\n\nexport default function Chapter12Page() {\n  return (\n    <Layout>\n      <Wrapper>\n        <h1>⚖️ Chapter 12: Responsible AI & Fairness</h1>\n\n        <p>Responsible AI focuses on building trustworthy, transparent, and fair machine learning systems. This chapter outlines ethical principles and implementation best practices using AWS and general ML approaches.</p>\n\n        <h2>📌 Core Principles of Responsible AI</h2>\n        <ul>\n          <li><strong>Fairness:</strong> Preventing discrimination against individuals or groups.</li>\n          <li><strong>Transparency:</strong> Ensuring models are explainable and decisions are understandable.</li>\n          <li><strong>Accountability:</strong> Defining roles for monitoring and responding to AI performance.</li>\n          <li><strong>Privacy:</strong> Respecting user data and minimizing exposure.</li>\n          <li><strong>Security:</strong> Protecting models and data from misuse.</li>\n        </ul>\n\n        <h2>🚫 Bias in Machine Learning</h2>\n        <ul>\n          <li>Bias can enter through skewed data, label imbalance, or model assumptions.</li>\n          <li>Bias types: historical bias, representation bias, measurement bias.</li>\n          <li>Detect with audits and disparity metrics.</li>\n          <li>Mitigate with diverse datasets, rebalancing, or fairness-aware algorithms.</li>\n        </ul>\n\n        <h2>🔍 Explainability & Interpretability</h2>\n        <p>Tools and techniques to understand how models make decisions:</p>\n        <ul>\n          <li><strong>SHAP:</strong> Shows feature contribution to each prediction.</li>\n          <li><strong>LIME:</strong> Locally interpretable explanations for predictions.</li>\n          <li><strong>AWS Clarify:</strong> Explain model behavior, monitor bias, and feature attribution.</li>\n        </ul>\n\n        <h2>🔐 Privacy & Data Protection</h2>\n        <ul>\n          <li>Use anonymization, encryption, and data minimization.</li>\n          <li>Follow compliance (e.g., GDPR, HIPAA).</li>\n          <li>Use <code>S3</code> encryption, <code>KMS</code> for key management, and IAM roles.</li>\n        </ul>\n\n        <h2>🧠 Monitoring & Governance</h2>\n        <ul>\n          <li>Track model behavior in production using <strong>Amazon SageMaker Model Monitor</strong>.</li>\n          <li>Alert on drift, bias, or violations.</li>\n          <li>Maintain audit logs of decisions, data, and deployments.</li>\n        </ul>\n\n        <h2>📉 Real-World Scenarios</h2>\n        <ul>\n          <li>Hiring tools that unfairly prefer one group over another.</li>\n          <li>Loan approvals with data skewed toward specific demographics.</li>\n          <li>Voice assistants that don't recognize diverse accents well.</li>\n        </ul>\n\n        <h2>🧭 Diagram: Responsible AI Lifecycle</h2>\n        <div className=\"diagram\">{`\n[ Data Collection ]\n       ↓\n[ Bias Detection & Audits ]\n       ↓\n[ Training with Fairness Constraints ]\n       ↓\n[ Explainability & Transparency Checks ]\n       ↓\n[ Secure Deployment + Monitoring ]\n       ↓\n[ Feedback Loops & Retraining ]\n        `}</div>\n\n        <h2>✅ Key Takeaways</h2>\n        <ul>\n          <li>Bias can enter at multiple stages – be proactive in monitoring and mitigation.</li>\n          <li>Responsible AI aligns model performance with ethical principles.</li>\n          <li>AWS tools like SageMaker Clarify and Model Monitor support fairness and explainability.</li>\n        </ul>\n\n        <FlashcardsChapter12 />\n                <ButtonGroup>\n                         <Link to=\"/quiz-chapter-12\">📝 Quiz</Link>\n                         <Link to=\"/\">🏠 Back to Home</Link>\n                       </ButtonGroup>\n      </Wrapper>\n    </Layout>\n  )\n}\n\nexport { Head }\n"],"names":["_ref","children","isFullWidth","React","style","margin","maxWidth","padding","marginTop","fontSize","color","Date","getFullYear","Head","title","description","siteTitle","siteDescription","name","content","property","fadeIn","keyframes","Card","styled","div","withConfig","displayName","componentId","Button","button","flashcards","question","answer","FlashcardsChapter12","shuffledCards","shuffleArray","array","_toConsumableArray","sort","Math","random","index","setIndex","showAnswer","setShowAnswer","length","onClick","prev","nextCard","marginLeft","ButtonGroup","Wrapper","Chapter12Page","Layout","className","Link","to"],"sourceRoot":""}